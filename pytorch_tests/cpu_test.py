"""
PyTorch CPU ì§‘ì•½ì  í…ŒìŠ¤íŠ¸
ì´ í…ŒìŠ¤íŠ¸ëŠ” CPU ì‚¬ìš©ë¥ ì„ ìµœëŒ€í™”í•˜ì—¬ CPU ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.
"""

import torch
import torch.nn as nn
import torch.optim as optim
import multiprocessing as mp
import numpy as np
import time
import argparse
import sys
import os

# Add utils directory to path
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))
from utils.resource_monitor import ResourceMonitor, print_system_info


def cpu_intensive_matrix_operations(size=2000, iterations=100):
    """CPU ì§‘ì•½ì  í–‰ë ¬ ì—°ì‚°"""
    print(f"Starting CPU intensive matrix operations (size: {size}x{size}, iterations: {iterations})")
    
    # CPUì—ì„œë§Œ ë™ì‘í•˜ë„ë¡ ì„¤ì •
    torch.set_num_threads(mp.cpu_count())
    
    results = []
    for i in range(iterations):
        # ëœë¤ í–‰ë ¬ ìƒì„±
        a = torch.randn(size, size, dtype=torch.float32)
        b = torch.randn(size, size, dtype=torch.float32)
        
        # ë‹¤ì–‘í•œ CPU ì§‘ì•½ì  ì—°ì‚°
        # 1. í–‰ë ¬ ê³±ì…ˆ
        c = torch.matmul(a, b)
        
        # 2. ê³ ìœ ê°’ ë¶„í•´ (ë§¤ìš° CPU ì§‘ì•½ì )
        if i % 10 == 0:  # 10ë²ˆë§ˆë‹¤ í•œ ë²ˆì”© ì‹¤í–‰
            try:
                eigenvalues, eigenvectors = torch.linalg.eig(c[:500, :500])  # í¬ê¸° ì¤„ì—¬ì„œ ì‹¤í–‰
                results.append(eigenvalues.real.mean().item())
            except:
                pass
        
        # 3. SVD ë¶„í•´
        if i % 5 == 0:  # 5ë²ˆë§ˆë‹¤ í•œ ë²ˆì”© ì‹¤í–‰
            try:
                u, s, v = torch.linalg.svd(c[:200, :200])
                results.append(s.mean().item())
            except:
                pass
        
        # 4. ì—­í–‰ë ¬ ê³„ì‚°
        try:
            c_inv = torch.linalg.inv(c + torch.eye(size) * 1e-5)  # ìˆ˜ì¹˜ì  ì•ˆì •ì„±ì„ ìœ„í•œ regularization
            results.append(c_inv.trace().item())
        except:
            pass
        
        # 5. ë³µì¡í•œ ìˆ˜í•™ ì—°ì‚°
        d = torch.sin(c) + torch.cos(c) + torch.exp(torch.clamp(c, -5, 5))
        results.append(d.mean().item())
        
        if i % 10 == 0:
            print(f"  Iteration {i}/{iterations} completed")
    
    return np.mean(results)


def cpu_parallel_processing(num_processes=None, work_per_process=50):
    """ë©€í‹°í”„ë¡œì„¸ì‹±ì„ ì‚¬ìš©í•œ CPU ë³‘ë ¬ ì²˜ë¦¬"""
    if num_processes is None:
        num_processes = mp.cpu_count()
    
    print(f"Starting CPU parallel processing ({num_processes} processes)")
    
    def worker_function(worker_id):
        """ê° í”„ë¡œì„¸ìŠ¤ì—ì„œ ì‹¤í–‰í•  ì‘ì—…"""
        results = []
        for i in range(work_per_process):
            # CPU ì§‘ì•½ì  ì—°ì‚°
            size = 1000
            a = torch.randn(size, size)
            b = torch.randn(size, size)
            
            # í–‰ë ¬ ì—°ì‚°
            c = torch.matmul(a, b)
            d = torch.matmul(c, a.t())
            
            # í†µê³„ ê³„ì‚°
            result = {
                'mean': d.mean().item(),
                'std': d.std().item(),
                'max': d.max().item(),
                'min': d.min().item()
            }
            results.append(result)
        
        return f"Worker {worker_id} completed {len(results)} operations"
    
    # ë©€í‹°í”„ë¡œì„¸ì‹± ì‹¤í–‰
    with mp.Pool(processes=num_processes) as pool:
        results = pool.map(worker_function, range(num_processes))
    
    return results


def neural_network_cpu_training(epochs=50, batch_size=1024):
    """CPUì—ì„œ ì‹ ê²½ë§ í•™ìŠµ"""
    print(f"Starting neural network training on CPU (epochs: {epochs}, batch_size: {batch_size})")
    
    # CPUì—ì„œë§Œ ë™ì‘í•˜ë„ë¡ ê°•ì œ
    device = torch.device('cpu')
    
    # ë³µì¡í•œ ì‹ ê²½ë§ ëª¨ë¸ ì •ì˜
    class ComplexCPUModel(nn.Module):
        def __init__(self):
            super(ComplexCPUModel, self).__init__()
            self.layers = nn.Sequential(
                nn.Linear(784, 2048),
                nn.ReLU(),
                nn.BatchNorm1d(2048),
                nn.Linear(2048, 1024),
                nn.ReLU(),
                nn.BatchNorm1d(1024),
                nn.Linear(1024, 512),
                nn.ReLU(),
                nn.BatchNorm1d(512),
                nn.Linear(512, 256),
                nn.ReLU(),
                nn.BatchNorm1d(256),
                nn.Linear(256, 128),
                nn.ReLU(),
                nn.Linear(128, 10)
            )
        
        def forward(self, x):
            return self.layers(x)
    
    model = ComplexCPUModel().to(device)
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=0.001)
    
    # ê°€ì§œ ë°ì´í„° ìƒì„±
    def generate_batch():
        x = torch.randn(batch_size, 784).to(device)
        y = torch.randint(0, 10, (batch_size,)).to(device)
        return x, y
    
    losses = []
    for epoch in range(epochs):
        epoch_loss = 0
        num_batches = 10  # ì—í¬í¬ë‹¹ ë°°ì¹˜ ìˆ˜
        
        for batch_idx in range(num_batches):
            x, y = generate_batch()
            
            optimizer.zero_grad()
            output = model(x)
            loss = criterion(output, y)
            loss.backward()
            optimizer.step()
            
            epoch_loss += loss.item()
        
        avg_loss = epoch_loss / num_batches
        losses.append(avg_loss)
        
        if epoch % 10 == 0:
            print(f"  Epoch {epoch}/{epochs}, Average Loss: {avg_loss:.4f}")
    
    return losses


def fibonacci_cpu_intensive(n=40):
    """CPU ì§‘ì•½ì  í”¼ë³´ë‚˜ì¹˜ ê³„ì‚°"""
    print(f"Starting CPU intensive Fibonacci calculation (n={n})")
    
    def fibonacci_recursive(n):
        if n <= 1:
            return n
        return fibonacci_recursive(n-1) + fibonacci_recursive(n-2)
    
    # ì—¬ëŸ¬ ê°œì˜ í”¼ë³´ë‚˜ì¹˜ ê³„ì‚°ì„ ë³‘ë ¬ë¡œ ì‹¤í–‰
    num_workers = mp.cpu_count()
    
    with mp.Pool(processes=num_workers) as pool:
        results = pool.map(fibonacci_recursive, [n-i for i in range(num_workers)])
    
    return results


def main():
    parser = argparse.ArgumentParser(description='PyTorch CPU ì§‘ì•½ì  í…ŒìŠ¤íŠ¸')
    parser.add_argument('--duration', type=int, default=60, help='í…ŒìŠ¤íŠ¸ ì§€ì† ì‹œê°„ (ì´ˆ)')
    parser.add_argument('--matrix-size', type=int, default=1500, help='í–‰ë ¬ í¬ê¸°')
    parser.add_argument('--iterations', type=int, default=50, help='ë°˜ë³µ íšŸìˆ˜')
    parser.add_argument('--skip-parallel', action='store_true', help='ë³‘ë ¬ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸ ê±´ë„ˆë›°ê¸°')
    parser.add_argument('--skip-training', action='store_true', help='ì‹ ê²½ë§ í•™ìŠµ í…ŒìŠ¤íŠ¸ ê±´ë„ˆë›°ê¸°')
    parser.add_argument('--skip-fibonacci', action='store_true', help='í”¼ë³´ë‚˜ì¹˜ í…ŒìŠ¤íŠ¸ ê±´ë„ˆë›°ê¸°')
    
    args = parser.parse_args()
    
    # ì‹œìŠ¤í…œ ì •ë³´ ì¶œë ¥
    print_system_info()
    
    # ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§ ì‹œì‘
    monitor = ResourceMonitor(interval=0.5)
    monitor.start_monitoring()
    
    print(f"\nğŸ”¥ PyTorch CPU ì§‘ì•½ì  í…ŒìŠ¤íŠ¸ ì‹œì‘ (ì§€ì† ì‹œê°„: {args.duration}ì´ˆ)")
    print("=" * 60)
    
    start_time = time.time()
    
    try:
        # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        test_results = {}
        
        # 1. í–‰ë ¬ ì—°ì‚° í…ŒìŠ¤íŠ¸
        print("\n1. í–‰ë ¬ ì—°ì‚° í…ŒìŠ¤íŠ¸")
        result = cpu_intensive_matrix_operations(size=args.matrix_size, iterations=args.iterations)
        test_results['matrix_operations'] = result
        
        # 2. ë³‘ë ¬ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸
        if not args.skip_parallel:
            print("\n2. ë³‘ë ¬ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸")
            result = cpu_parallel_processing()
            test_results['parallel_processing'] = result
        
        # 3. ì‹ ê²½ë§ í•™ìŠµ í…ŒìŠ¤íŠ¸
        if not args.skip_training:
            print("\n3. ì‹ ê²½ë§ í•™ìŠµ í…ŒìŠ¤íŠ¸")
            result = neural_network_cpu_training(epochs=30)
            test_results['neural_network'] = result
        
        # 4. í”¼ë³´ë‚˜ì¹˜ í…ŒìŠ¤íŠ¸
        if not args.skip_fibonacci:
            print("\n4. í”¼ë³´ë‚˜ì¹˜ í…ŒìŠ¤íŠ¸")
            result = fibonacci_cpu_intensive(n=35)
            test_results['fibonacci'] = result
        
        # ë‚¨ì€ ì‹œê°„ ë™ì•ˆ ì¶”ê°€ í–‰ë ¬ ì—°ì‚° ìˆ˜í–‰
        elapsed_time = time.time() - start_time
        remaining_time = args.duration - elapsed_time
        
        if remaining_time > 5:
            print(f"\n5. ì¶”ê°€ í–‰ë ¬ ì—°ì‚° ({remaining_time:.1f}ì´ˆ ë™ì•ˆ)")
            extra_iterations = max(10, int(remaining_time / 2))
            result = cpu_intensive_matrix_operations(size=1000, iterations=extra_iterations)
            test_results['extra_operations'] = result
        
    except KeyboardInterrupt:
        print("\ní…ŒìŠ¤íŠ¸ê°€ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"\ní…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    finally:
        # ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§ ì¢…ë£Œ
        monitor.stop_monitoring()
        monitor.print_summary()
        
        # ìµœì¢… ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ í™•ì¸
        final_usage = monitor.get_current_usage()
        print(f"\nìµœì¢… ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰:")
        print(f"CPU: {final_usage.get('cpu_percent', 0):.1f}%")
        print(f"Memory: {final_usage.get('memory_percent', 0):.1f}%")
        
        print("\nğŸ¯ PyTorch CPU ì§‘ì•½ì  í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        print("=" * 60)


if __name__ == "__main__":
    # PyTorch ì„¤ì •
    torch.set_num_threads(mp.cpu_count())  # ëª¨ë“  CPU ì½”ì–´ ì‚¬ìš©
    
    main() 