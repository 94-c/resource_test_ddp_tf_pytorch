"""
PyTorch GPU ë©”ëª¨ë¦¬ ì§‘ì•½ì  í…ŒìŠ¤íŠ¸
ì´ í…ŒìŠ¤íŠ¸ëŠ” GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ ìµœëŒ€í™”í•˜ì—¬ GPU ë©”ëª¨ë¦¬ ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import time
import argparse
import sys
import os
import gc
from typing import List, Dict, Optional

# Add utils directory to path
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))
from utils.resource_monitor import ResourceMonitor, print_system_info


class GPUMemoryConsumer:
    """GPU ë©”ëª¨ë¦¬ ì†Œë¹„ì í´ë˜ìŠ¤"""
    def __init__(self):
        self.gpu_tensors = []
        self.gpu_models = []
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
        if not torch.cuda.is_available():
            print("âš ï¸  CUDAê°€ ì‚¬ìš© ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤. CPU ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤.")
        else:
            print(f"âœ… CUDA ì‚¬ìš© ê°€ëŠ¥: {torch.cuda.get_device_name()}")
            print(f"   GPU ë©”ëª¨ë¦¬: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
    
    def allocate_large_gpu_tensors(self, num_tensors=50, tensor_size=(4000, 4000)):
        """ëŒ€ëŸ‰ì˜ í…ì„œë¥¼ GPU ë©”ëª¨ë¦¬ì— í• ë‹¹"""
        if not torch.cuda.is_available():
            print("GPUê°€ ì‚¬ìš© ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤. í…ŒìŠ¤íŠ¸ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
            return []
        
        print(f"GPUì— {num_tensors}ê°œì˜ ëŒ€ìš©ëŸ‰ í…ì„œ í• ë‹¹ (í¬ê¸°: {tensor_size})")
        
        tensors = []
        for i in range(num_tensors):
            try:
                # ë‹¤ì–‘í•œ ë°ì´í„° íƒ€ì…ìœ¼ë¡œ GPU í…ì„œ ìƒì„±
                if i % 3 == 0:
                    tensor = torch.randn(tensor_size, dtype=torch.float32, device=self.device)
                elif i % 3 == 1:
                    tensor = torch.randn(tensor_size, dtype=torch.float16, device=self.device)  # ë©”ëª¨ë¦¬ ì ˆì•½
                else:
                    tensor = torch.randint(0, 100, tensor_size, dtype=torch.int32, device=self.device)
                
                tensors.append(tensor)
                
                if i % 10 == 0:
                    allocated_memory = torch.cuda.memory_allocated() / 1024**3
                    print(f"  í• ë‹¹ë¨ {i+1}/{num_tensors}, GPU ë©”ëª¨ë¦¬: {allocated_memory:.2f} GB")
                    
            except RuntimeError as e:
                if "out of memory" in str(e):
                    print(f"  GPU ë©”ëª¨ë¦¬ ë¶€ì¡±ìœ¼ë¡œ {i}ë²ˆì§¸ í…ì„œì—ì„œ ì¤‘ë‹¨")
                    break
                else:
                    raise e
        
        self.gpu_tensors.extend(tensors)
        return tensors
    
    def create_massive_gpu_model(self, input_size=20000):
        """ëŒ€ìš©ëŸ‰ GPU ëª¨ë¸ ìƒì„±"""
        if not torch.cuda.is_available():
            print("GPUê°€ ì‚¬ìš© ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤. í…ŒìŠ¤íŠ¸ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
            return None
        
        print(f"ëŒ€ìš©ëŸ‰ GPU ëª¨ë¸ ìƒì„± (ì…ë ¥ í¬ê¸°: {input_size})")
        
        class MassiveGPUModel(nn.Module):
            def __init__(self, input_size):
                super(MassiveGPUModel, self).__init__()
                
                # ë§¤ìš° í° ë ˆì´ì–´ë“¤
                self.layers = nn.ModuleList([
                    nn.Linear(input_size, 16384),
                    nn.Linear(16384, 8192),
                    nn.Linear(8192, 4096),
                    nn.Linear(4096, 2048),
                    nn.Linear(2048, 1024),
                    nn.Linear(1024, 512),
                    nn.Linear(512, 256),
                    nn.Linear(256, 128),
                    nn.Linear(128, 64),
                    nn.Linear(64, 10)
                ])
                
                # ë°°ì¹˜ ì •ê·œí™” ë ˆì´ì–´ë“¤
                self.batch_norms = nn.ModuleList([
                    nn.BatchNorm1d(16384),
                    nn.BatchNorm1d(8192),
                    nn.BatchNorm1d(4096),
                    nn.BatchNorm1d(2048),
                    nn.BatchNorm1d(1024),
                    nn.BatchNorm1d(512),
                    nn.BatchNorm1d(256),
                    nn.BatchNorm1d(128),
                    nn.BatchNorm1d(64)
                ])
                
                # ë“œë¡­ì•„ì›ƒ ë ˆì´ì–´ë“¤
                self.dropouts = nn.ModuleList([nn.Dropout(0.2) for _ in range(9)])
            
            def forward(self, x):
                for i, (layer, bn, dropout) in enumerate(zip(self.layers[:-1], self.batch_norms, self.dropouts)):
                    x = layer(x)
                    x = F.relu(x)
                    x = bn(x)
                    x = dropout(x)
                
                x = self.layers[-1](x)  # ë§ˆì§€ë§‰ ë ˆì´ì–´
                return x
        
        try:
            model = MassiveGPUModel(input_size).to(self.device)
            total_params = sum(p.numel() for p in model.parameters())
            model_size_mb = sum(p.numel() * p.element_size() for p in model.parameters()) / 1024**2
            
            print(f"  ëª¨ë¸ ìƒì„± ì™„ë£Œ: {total_params:,} íŒŒë¼ë¯¸í„°, {model_size_mb:.1f} MB")
            
            self.gpu_models.append(model)
            return model
            
        except RuntimeError as e:
            if "out of memory" in str(e):
                print(f"  GPU ë©”ëª¨ë¦¬ ë¶€ì¡±ìœ¼ë¡œ ëª¨ë¸ ìƒì„± ì‹¤íŒ¨")
                return None
            else:
                raise e
    
    def progressive_gpu_memory_allocation(self, max_iterations=100, size_multiplier=1.05):
        """ì ì§„ì  GPU ë©”ëª¨ë¦¬ í• ë‹¹"""
        if not torch.cuda.is_available():
            print("GPUê°€ ì‚¬ìš© ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤. í…ŒìŠ¤íŠ¸ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
            return []
        
        print(f"ì ì§„ì  GPU ë©”ëª¨ë¦¬ í• ë‹¹ ({max_iterations} ë°˜ë³µ)")
        
        current_size = 1000
        allocated_tensors = []
        
        for i in range(max_iterations):
            try:
                tensor_size = int(current_size)
                tensor = torch.randn(tensor_size, tensor_size, dtype=torch.float32, device=self.device)
                allocated_tensors.append(tensor)
                
                current_size *= size_multiplier
                
                if i % 10 == 0:
                    gpu_memory = torch.cuda.memory_allocated() / 1024**3
                    print(f"  ë°˜ë³µ {i}: GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ {gpu_memory:.2f} GB")
                    
            except RuntimeError as e:
                if "out of memory" in str(e):
                    print(f"  GPU ë©”ëª¨ë¦¬ í•œê³„ì— ë„ë‹¬: ë°˜ë³µ {i}")
                    break
                else:
                    raise e
        
        return allocated_tensors
    
    def gpu_memory_stress_test(self, stress_level=5):
        """GPU ë©”ëª¨ë¦¬ ìŠ¤íŠ¸ë ˆìŠ¤ í…ŒìŠ¤íŠ¸"""
        if not torch.cuda.is_available():
            print("GPUê°€ ì‚¬ìš© ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤. í…ŒìŠ¤íŠ¸ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
            return
        
        print(f"GPU ë©”ëª¨ë¦¬ ìŠ¤íŠ¸ë ˆìŠ¤ í…ŒìŠ¤íŠ¸ (ë ˆë²¨: {stress_level})")
        
        # ìŠ¤íŠ¸ë ˆìŠ¤ ë ˆë²¨ì— ë”°ë¥¸ í…ì„œ í¬ê¸° ì¡°ì •
        base_size = 2000
        tensor_size = base_size * stress_level
        
        stress_tensors = []
        
        for i in range(20):
            try:
                # ë‹¤ì–‘í•œ ì—°ì‚°ìœ¼ë¡œ GPU ë©”ëª¨ë¦¬ ì‚¬ìš©
                a = torch.randn(tensor_size, tensor_size, device=self.device)
                b = torch.randn(tensor_size, tensor_size, device=self.device)
                
                # í–‰ë ¬ ê³±ì…ˆ
                c = torch.matmul(a, b)
                
                # ì¶”ê°€ ì—°ì‚°
                d = torch.sin(c) + torch.cos(c)
                e = torch.matmul(d, a.t())
                
                stress_tensors.append(e)
                
                if i % 5 == 0:
                    gpu_memory = torch.cuda.memory_allocated() / 1024**3
                    print(f"  ìŠ¤íŠ¸ë ˆìŠ¤ {i}: GPU ë©”ëª¨ë¦¬ {gpu_memory:.2f} GB")
                    
            except RuntimeError as e:
                if "out of memory" in str(e):
                    print(f"  ìŠ¤íŠ¸ë ˆìŠ¤ í…ŒìŠ¤íŠ¸ ì¤‘ ë©”ëª¨ë¦¬ ë¶€ì¡±: ë‹¨ê³„ {i}")
                    break
                else:
                    raise e
        
        return stress_tensors
    
    def multi_gpu_memory_test(self):
        """ë‹¤ì¤‘ GPU ë©”ëª¨ë¦¬ í…ŒìŠ¤íŠ¸"""
        if not torch.cuda.is_available():
            print("GPUê°€ ì‚¬ìš© ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤. í…ŒìŠ¤íŠ¸ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
            return
        
        gpu_count = torch.cuda.device_count()
        print(f"ë‹¤ì¤‘ GPU ë©”ëª¨ë¦¬ í…ŒìŠ¤íŠ¸ ({gpu_count}ê°œ GPU)")
        
        if gpu_count < 2:
            print("ë‹¨ì¼ GPU í™˜ê²½ì—ì„œ ë‹¤ì¤‘ GPU ì‹œë®¬ë ˆì´ì…˜")
            gpu_count = 1
        
        gpu_tensors = {}
        
        for gpu_id in range(gpu_count):
            try:
                device = torch.device(f'cuda:{gpu_id}')
                print(f"  GPU {gpu_id}ì— í…ì„œ í• ë‹¹ ì¤‘...")
                
                tensors = []
                for i in range(10):
                    tensor = torch.randn(3000, 3000, device=device)
                    tensors.append(tensor)
                
                gpu_tensors[gpu_id] = tensors
                
                gpu_memory = torch.cuda.memory_allocated(gpu_id) / 1024**3
                print(f"  GPU {gpu_id}: {gpu_memory:.2f} GB í• ë‹¹ë¨")
                
            except RuntimeError as e:
                if "out of memory" in str(e):
                    print(f"  GPU {gpu_id} ë©”ëª¨ë¦¬ ë¶€ì¡±")
                else:
                    raise e
        
        return gpu_tensors
    
    def clear_gpu_memory(self):
        """GPU ë©”ëª¨ë¦¬ ì •ë¦¬"""
        print("GPU ë©”ëª¨ë¦¬ ì •ë¦¬ ì¤‘...")
        
        self.gpu_tensors.clear()
        self.gpu_models.clear()
        
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
            torch.cuda.synchronize()
            
            print(f"ì •ë¦¬ í›„ GPU ë©”ëª¨ë¦¬: {torch.cuda.memory_allocated() / 1024**3:.2f} GB")


def gpu_training_memory_test(batch_size=256, num_epochs=20, model_size='large'):
    """GPU í•™ìŠµ ë©”ëª¨ë¦¬ í…ŒìŠ¤íŠ¸"""
    if not torch.cuda.is_available():
        print("GPUê°€ ì‚¬ìš© ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤. í…ŒìŠ¤íŠ¸ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
        return
    
    device = torch.device('cuda')
    print(f"GPU í•™ìŠµ ë©”ëª¨ë¦¬ í…ŒìŠ¤íŠ¸ (ë°°ì¹˜: {batch_size}, ì—í¬í¬: {num_epochs})")
    
    # ëª¨ë¸ í¬ê¸°ì— ë”°ë¥¸ ì„¤ì •
    if model_size == 'large':
        input_size, hidden_size = 5000, 2048
    elif model_size == 'medium':
        input_size, hidden_size = 2000, 1024
    else:
        input_size, hidden_size = 1000, 512
    
    # ëª¨ë¸ ìƒì„±
    model = nn.Sequential(
        nn.Linear(input_size, hidden_size),
        nn.ReLU(),
        nn.BatchNorm1d(hidden_size),
        nn.Linear(hidden_size, hidden_size // 2),
        nn.ReLU(),
        nn.BatchNorm1d(hidden_size // 2),
        nn.Linear(hidden_size // 2, hidden_size // 4),
        nn.ReLU(),
        nn.Linear(hidden_size // 4, 100)
    ).to(device)
    
    criterion = nn.CrossEntropyLoss()
    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
    
    # í•™ìŠµ ë£¨í”„
    for epoch in range(num_epochs):
        epoch_memory_usage = []
        
        for batch_idx in range(20):  # ì—í¬í¬ë‹¹ 20 ë°°ì¹˜
            # ë°°ì¹˜ ë°ì´í„° ìƒì„±
            X = torch.randn(batch_size, input_size, device=device)
            y = torch.randint(0, 100, (batch_size,), device=device)
            
            # ìˆœì „íŒŒ
            optimizer.zero_grad()
            output = model(X)
            loss = criterion(output, y)
            
            # ì—­ì „íŒŒ
            loss.backward()
            optimizer.step()
            
            # GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê¸°ë¡
            gpu_memory = torch.cuda.memory_allocated() / 1024**3
            epoch_memory_usage.append(gpu_memory)
        
        avg_memory = np.mean(epoch_memory_usage)
        max_memory = np.max(epoch_memory_usage)
        
        if epoch % 5 == 0:
            print(f"  ì—í¬í¬ {epoch}: í‰ê·  GPU ë©”ëª¨ë¦¬ {avg_memory:.2f} GB, ìµœëŒ€ {max_memory:.2f} GB")


def main():
    parser = argparse.ArgumentParser(description='PyTorch GPU ë©”ëª¨ë¦¬ ì§‘ì•½ì  í…ŒìŠ¤íŠ¸')
    parser.add_argument('--duration', type=int, default=180, help='í…ŒìŠ¤íŠ¸ ì§€ì† ì‹œê°„ (ì´ˆ)')
    parser.add_argument('--num-tensors', type=int, default=30, help='í• ë‹¹í•  GPU í…ì„œ ìˆ˜')
    parser.add_argument('--tensor-size', type=int, default=3000, help='í…ì„œ í¬ê¸°')
    parser.add_argument('--stress-level', type=int, default=3, help='ìŠ¤íŠ¸ë ˆìŠ¤ í…ŒìŠ¤íŠ¸ ë ˆë²¨ (1-5)')
    parser.add_argument('--skip-progressive', action='store_true', help='ì ì§„ì  í• ë‹¹ í…ŒìŠ¤íŠ¸ ê±´ë„ˆë›°ê¸°')
    parser.add_argument('--skip-stress', action='store_true', help='ìŠ¤íŠ¸ë ˆìŠ¤ í…ŒìŠ¤íŠ¸ ê±´ë„ˆë›°ê¸°')
    parser.add_argument('--skip-training', action='store_true', help='í•™ìŠµ í…ŒìŠ¤íŠ¸ ê±´ë„ˆë›°ê¸°')
    parser.add_argument('--skip-multi-gpu', action='store_true', help='ë‹¤ì¤‘ GPU í…ŒìŠ¤íŠ¸ ê±´ë„ˆë›°ê¸°')
    
    args = parser.parse_args()
    
    # ì‹œìŠ¤í…œ ì •ë³´ ì¶œë ¥
    print_system_info()
    
    # GPU ì •ë³´ ì¶œë ¥
    if torch.cuda.is_available():
        print(f"\nğŸ® GPU ì •ë³´:")
        print(f"  ë””ë°”ì´ìŠ¤: {torch.cuda.get_device_name()}")
        print(f"  ë©”ëª¨ë¦¬: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
        print(f"  GPU ê°œìˆ˜: {torch.cuda.device_count()}")
    
    # ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§ ì‹œì‘
    monitor = ResourceMonitor(interval=0.5)
    monitor.start_monitoring()
    
    print(f"\nğŸ¯ PyTorch GPU ë©”ëª¨ë¦¬ ì§‘ì•½ì  í…ŒìŠ¤íŠ¸ ì‹œì‘ (ì§€ì† ì‹œê°„: {args.duration}ì´ˆ)")
    print("=" * 60)
    
    # GPU ë©”ëª¨ë¦¬ ì†Œë¹„ì ìƒì„±
    gpu_consumer = GPUMemoryConsumer()
    
    start_time = time.time()
    
    try:
        # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        test_results = {}
        
        # 1. ëŒ€ëŸ‰ GPU í…ì„œ í• ë‹¹
        print("\n1. ëŒ€ëŸ‰ GPU í…ì„œ í• ë‹¹ í…ŒìŠ¤íŠ¸")
        gpu_tensors = gpu_consumer.allocate_large_gpu_tensors(
            num_tensors=args.num_tensors,
            tensor_size=(args.tensor_size, args.tensor_size)
        )
        test_results['gpu_tensors'] = len(gpu_tensors)
        
        # 2. ëŒ€ìš©ëŸ‰ GPU ëª¨ë¸ ìƒì„±
        print("\n2. ëŒ€ìš©ëŸ‰ GPU ëª¨ë¸ ìƒì„±")
        gpu_model = gpu_consumer.create_massive_gpu_model(input_size=10000)
        test_results['gpu_model'] = gpu_model is not None
        
        # 3. ì ì§„ì  GPU ë©”ëª¨ë¦¬ í• ë‹¹
        if not args.skip_progressive:
            print("\n3. ì ì§„ì  GPU ë©”ëª¨ë¦¬ í• ë‹¹")
            progressive_tensors = gpu_consumer.progressive_gpu_memory_allocation(max_iterations=50)
            test_results['progressive_tensors'] = len(progressive_tensors)
        
        # 4. GPU ë©”ëª¨ë¦¬ ìŠ¤íŠ¸ë ˆìŠ¤ í…ŒìŠ¤íŠ¸
        if not args.skip_stress:
            print("\n4. GPU ë©”ëª¨ë¦¬ ìŠ¤íŠ¸ë ˆìŠ¤ í…ŒìŠ¤íŠ¸")
            stress_tensors = gpu_consumer.gpu_memory_stress_test(stress_level=args.stress_level)
            test_results['stress_tensors'] = len(stress_tensors) if stress_tensors else 0
        
        # 5. ë‹¤ì¤‘ GPU ë©”ëª¨ë¦¬ í…ŒìŠ¤íŠ¸
        if not args.skip_multi_gpu:
            print("\n5. ë‹¤ì¤‘ GPU ë©”ëª¨ë¦¬ í…ŒìŠ¤íŠ¸")
            multi_gpu_tensors = gpu_consumer.multi_gpu_memory_test()
            test_results['multi_gpu_tensors'] = len(multi_gpu_tensors) if multi_gpu_tensors else 0
        
        # 6. GPU í•™ìŠµ ë©”ëª¨ë¦¬ í…ŒìŠ¤íŠ¸
        if not args.skip_training:
            print("\n6. GPU í•™ìŠµ ë©”ëª¨ë¦¬ í…ŒìŠ¤íŠ¸")
            gpu_training_memory_test(batch_size=128, num_epochs=15, model_size='large')
            test_results['training_completed'] = True
        
        # ë‚¨ì€ ì‹œê°„ ë™ì•ˆ ì¶”ê°€ GPU í…ì„œ í• ë‹¹
        elapsed_time = time.time() - start_time
        remaining_time = args.duration - elapsed_time
        
        if remaining_time > 15:
            print(f"\n7. ì¶”ê°€ GPU í…ì„œ í• ë‹¹ ({remaining_time:.1f}ì´ˆ ë™ì•ˆ)")
            extra_tensors = gpu_consumer.allocate_large_gpu_tensors(
                num_tensors=max(5, int(remaining_time / 10)),
                tensor_size=(2000, 2000)
            )
            test_results['extra_tensors'] = len(extra_tensors)
        
    except KeyboardInterrupt:
        print("\ní…ŒìŠ¤íŠ¸ê°€ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"\ní…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
    finally:
        # ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§ ì¢…ë£Œ
        monitor.stop_monitoring()
        monitor.print_summary()
        
        # ìµœì¢… ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ í™•ì¸
        final_usage = monitor.get_current_usage()
        print(f"\nìµœì¢… ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰:")
        if torch.cuda.is_available():
            for i in range(torch.cuda.device_count()):
                gpu_memory = torch.cuda.memory_allocated(i) / 1024**3
                print(f"GPU {i} ë©”ëª¨ë¦¬: {gpu_memory:.2f} GB")
        
        # GPU ë©”ëª¨ë¦¬ ì •ë¦¬
        print("\nGPU ë©”ëª¨ë¦¬ ì •ë¦¬ ì¤‘...")
        gpu_consumer.clear_gpu_memory()
        
        print("\nğŸ¯ PyTorch GPU ë©”ëª¨ë¦¬ ì§‘ì•½ì  í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        print("=" * 60)


if __name__ == "__main__":
    main() 