"""
TensorFlow CPU ì§‘ì•½ì  í…ŒìŠ¤íŠ¸
ì´ í…ŒìŠ¤íŠ¸ëŠ” CPU ì‚¬ìš©ë¥ ì„ ìµœëŒ€í™”í•˜ì—¬ CPU ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.
"""

import tensorflow as tf
import numpy as np
import time
import argparse
import sys
import os
import multiprocessing as mp
from concurrent.futures import ThreadPoolExecutor
import threading

# Add utils directory to path
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))
from utils.resource_monitor import ResourceMonitor, print_system_info


def setup_tensorflow_cpu():
    """TensorFlow CPU ì„¤ì •"""
    # CPUë§Œ ì‚¬ìš©í•˜ë„ë¡ ì„¤ì •
    tf.config.set_visible_devices([], 'GPU')
    
    # CPU ìŠ¤ë ˆë“œ ìˆ˜ ì„¤ì •
    tf.config.threading.set_intra_op_parallelism_threads(mp.cpu_count())
    tf.config.threading.set_inter_op_parallelism_threads(mp.cpu_count())
    
    print(f"TensorFlow CPU ì„¤ì • ì™„ë£Œ - ìŠ¤ë ˆë“œ ìˆ˜: {mp.cpu_count()}")


def cpu_intensive_matrix_operations(num_iterations=200, matrix_size=2000):
    """CPU ì§‘ì•½ì  í–‰ë ¬ ì—°ì‚°"""
    print(f"TensorFlow CPU ì§‘ì•½ì  í–‰ë ¬ ì—°ì‚° (ë°˜ë³µ: {num_iterations}, í¬ê¸°: {matrix_size})")
    
    results = []
    
    for i in range(num_iterations):
        # ëœë¤ í–‰ë ¬ ìƒì„±
        a = tf.random.normal([matrix_size, matrix_size], dtype=tf.float32)
        b = tf.random.normal([matrix_size, matrix_size], dtype=tf.float32)
        
        # í–‰ë ¬ ê³±ì…ˆ
        c = tf.matmul(a, b)
        
        # ê³ ìœ ê°’ ë¶„í•´ (ë§¤ìš° CPU ì§‘ì•½ì )
        if i % 10 == 0:
            try:
                eigenvalues = tf.linalg.eigvals(c[:500, :500])
                results.append(tf.reduce_mean(tf.math.real(eigenvalues)).numpy())
            except:
                pass
        
        # SVD ë¶„í•´
        if i % 5 == 0:
            try:
                s, u, v = tf.linalg.svd(c[:300, :300])
                results.append(tf.reduce_mean(s).numpy())
            except:
                pass
        
        # ë³µì¡í•œ ìˆ˜í•™ ì—°ì‚°
        d = tf.sin(c) + tf.cos(c) + tf.exp(tf.clip_by_value(c, -5, 5))
        results.append(tf.reduce_mean(d).numpy())
        
        # ì—­í–‰ë ¬ ê³„ì‚°
        try:
            c_inv = tf.linalg.inv(c + tf.eye(matrix_size) * 1e-5)
            results.append(tf.linalg.trace(c_inv).numpy())
        except:
            pass
        
        if i % 20 == 0:
            print(f"  ë°˜ë³µ {i}/{num_iterations} ì™„ë£Œ")
    
    return np.mean(results)


def cpu_parallel_tensorflow_ops(num_threads=None, operations_per_thread=100):
    """ë³‘ë ¬ TensorFlow ì—°ì‚°"""
    if num_threads is None:
        num_threads = mp.cpu_count()
    
    print(f"ë³‘ë ¬ TensorFlow ì—°ì‚° ({num_threads} ìŠ¤ë ˆë“œ)")
    
    def worker_function(thread_id):
        """ê° ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰í•  TensorFlow ì—°ì‚°"""
        results = []
        
        for i in range(operations_per_thread):
            # í…ì„œ ìƒì„±
            size = 1000
            a = tf.random.normal([size, size])
            b = tf.random.normal([size, size])
            
            # í–‰ë ¬ ì—°ì‚°
            c = tf.matmul(a, b)
            d = tf.matmul(c, tf.transpose(a))
            
            # í†µê³„ ê³„ì‚°
            result = {
                'mean': tf.reduce_mean(d).numpy(),
                'std': tf.math.reduce_std(d).numpy(),
                'max': tf.reduce_max(d).numpy(),
                'min': tf.reduce_min(d).numpy()
            }
            results.append(result)
        
        return f"ìŠ¤ë ˆë“œ {thread_id} ì™„ë£Œ: {len(results)} ì—°ì‚°"
    
    # ìŠ¤ë ˆë“œ í’€ ì‹¤í–‰
    with ThreadPoolExecutor(max_workers=num_threads) as executor:
        futures = [executor.submit(worker_function, i) for i in range(num_threads)]
        results = [future.result() for future in futures]
    
    return results


def neural_network_cpu_training(epochs=40, batch_size=512):
    """CPUì—ì„œ ì‹ ê²½ë§ í•™ìŠµ"""
    print(f"TensorFlow CPU ì‹ ê²½ë§ í•™ìŠµ (ì—í¬í¬: {epochs}, ë°°ì¹˜: {batch_size})")
    
    # ë³µì¡í•œ ì‹ ê²½ë§ ëª¨ë¸ ì •ì˜
    model = tf.keras.Sequential([
        tf.keras.layers.Dense(2048, activation='relu', input_shape=(784,)),
        tf.keras.layers.BatchNormalization(),
        tf.keras.layers.Dropout(0.2),
        tf.keras.layers.Dense(1024, activation='relu'),
        tf.keras.layers.BatchNormalization(),
        tf.keras.layers.Dropout(0.2),
        tf.keras.layers.Dense(512, activation='relu'),
        tf.keras.layers.BatchNormalization(),
        tf.keras.layers.Dropout(0.2),
        tf.keras.layers.Dense(256, activation='relu'),
        tf.keras.layers.BatchNormalization(),
        tf.keras.layers.Dense(128, activation='relu'),
        tf.keras.layers.Dense(10, activation='softmax')
    ])
    
    # ëª¨ë¸ ì»´íŒŒì¼
    model.compile(
        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
        loss='sparse_categorical_crossentropy',
        metrics=['accuracy']
    )
    
    # ê°€ì§œ ë°ì´í„° ìƒì„±
    def generate_batch():
        x = tf.random.normal([batch_size, 784])
        y = tf.random.uniform([batch_size], 0, 10, dtype=tf.int32)
        return x, y
    
    # í•™ìŠµ ë£¨í”„
    losses = []
    for epoch in range(epochs):
        epoch_losses = []
        
        for batch in range(10):  # ì—í¬í¬ë‹¹ 10 ë°°ì¹˜
            x, y = generate_batch()
            
            # ê·¸ë˜ë””ì–¸íŠ¸ í…Œì´í”„ë¥¼ ì‚¬ìš©í•œ ìˆ˜ë™ í•™ìŠµ
            with tf.GradientTape() as tape:
                predictions = model(x, training=True)
                loss = tf.keras.losses.sparse_categorical_crossentropy(y, predictions)
                loss = tf.reduce_mean(loss)
            
            # ê·¸ë˜ë””ì–¸íŠ¸ ê³„ì‚° ë° ì ìš©
            gradients = tape.gradient(loss, model.trainable_variables)
            model.optimizer.apply_gradients(zip(gradients, model.trainable_variables))
            
            epoch_losses.append(loss.numpy())
        
        avg_loss = np.mean(epoch_losses)
        losses.append(avg_loss)
        
        if epoch % 10 == 0:
            print(f"  ì—í¬í¬ {epoch}/{epochs}, í‰ê·  ì†ì‹¤: {avg_loss:.4f}")
    
    return losses


def convolution_cpu_intensive(num_iterations=100, batch_size=16):
    """CPU ì§‘ì•½ì  ì»¨ë³¼ë£¨ì…˜ ì—°ì‚°"""
    print(f"TensorFlow CPU ì»¨ë³¼ë£¨ì…˜ ì—°ì‚° (ë°˜ë³µ: {num_iterations}, ë°°ì¹˜: {batch_size})")
    
    # ì»¨ë³¼ë£¨ì…˜ ëª¨ë¸ ìƒì„±
    model = tf.keras.Sequential([
        tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),
        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),
        tf.keras.layers.MaxPooling2D((2, 2)),
        tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),
        tf.keras.layers.Conv2D(256, (3, 3), activation='relu'),
        tf.keras.layers.MaxPooling2D((2, 2)),
        tf.keras.layers.Conv2D(512, (3, 3), activation='relu'),
        tf.keras.layers.GlobalAveragePooling2D(),
        tf.keras.layers.Dense(256, activation='relu'),
        tf.keras.layers.Dense(10, activation='softmax')
    ])
    
    model.compile(
        optimizer='adam',
        loss='sparse_categorical_crossentropy',
        metrics=['accuracy']
    )
    
    # í•™ìŠµ ë£¨í”„
    for i in range(num_iterations):
        # ëœë¤ ì´ë¯¸ì§€ ë°ì´í„° ìƒì„±
        x = tf.random.normal([batch_size, 224, 224, 3])
        y = tf.random.uniform([batch_size], 0, 10, dtype=tf.int32)
        
        # í•™ìŠµ ìŠ¤í…
        with tf.GradientTape() as tape:
            predictions = model(x, training=True)
            loss = tf.keras.losses.sparse_categorical_crossentropy(y, predictions)
            loss = tf.reduce_mean(loss)
        
        gradients = tape.gradient(loss, model.trainable_variables)
        model.optimizer.apply_gradients(zip(gradients, model.trainable_variables))
        
        if i % 20 == 0:
            print(f"  ì»¨ë³¼ë£¨ì…˜ ë°˜ë³µ {i}/{num_iterations}, ì†ì‹¤: {loss.numpy():.4f}")


def mathematical_intensive_operations(num_iterations=500):
    """ìˆ˜í•™ì  ì§‘ì•½ì  ì—°ì‚°"""
    print(f"TensorFlow ìˆ˜í•™ì  ì§‘ì•½ì  ì—°ì‚° (ë°˜ë³µ: {num_iterations})")
    
    for i in range(num_iterations):
        # ëŒ€ìš©ëŸ‰ í…ì„œ ìƒì„±
        size = 2000
        a = tf.random.normal([size, size])
        
        # ë³µì¡í•œ ìˆ˜í•™ ì—°ì‚°
        b = tf.sin(a) + tf.cos(a)
        c = tf.exp(tf.clip_by_value(b, -5, 5))
        d = tf.math.log(tf.abs(c) + 1e-8)
        e = tf.sqrt(tf.abs(d) + 1e-8)
        f = tf.pow(tf.abs(e), 0.5)
        
        # í–‰ë ¬ ì—°ì‚°
        g = tf.matmul(f, tf.transpose(f))
        
        # í†µê³„ ì—°ì‚°
        mean_val = tf.reduce_mean(g)
        std_val = tf.math.reduce_std(g)
        
        # ì†ŒíŒ… ì—°ì‚°
        if i % 20 == 0:
            sorted_vals = tf.sort(tf.reshape(g, [-1]))
        
        # ì¡°ê±´ë¶€ ì—°ì‚°
        mask = g > mean_val
        filtered = tf.where(mask, g, tf.zeros_like(g))
        
        if i % 50 == 0:
            print(f"  ìˆ˜í•™ ì—°ì‚° ë°˜ë³µ {i}/{num_iterations}")


def main():
    parser = argparse.ArgumentParser(description='TensorFlow CPU ì§‘ì•½ì  í…ŒìŠ¤íŠ¸')
    parser.add_argument('--duration', type=int, default=120, help='í…ŒìŠ¤íŠ¸ ì§€ì† ì‹œê°„ (ì´ˆ)')
    parser.add_argument('--matrix-iterations', type=int, default=100, help='í–‰ë ¬ ì—°ì‚° ë°˜ë³µ íšŸìˆ˜')
    parser.add_argument('--matrix-size', type=int, default=1500, help='í–‰ë ¬ í¬ê¸°')
    parser.add_argument('--epochs', type=int, default=30, help='ì‹ ê²½ë§ í•™ìŠµ ì—í¬í¬')
    parser.add_argument('--skip-parallel', action='store_true', help='ë³‘ë ¬ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸ ê±´ë„ˆë›°ê¸°')
    parser.add_argument('--skip-training', action='store_true', help='ì‹ ê²½ë§ í•™ìŠµ í…ŒìŠ¤íŠ¸ ê±´ë„ˆë›°ê¸°')
    parser.add_argument('--skip-conv', action='store_true', help='ì»¨ë³¼ë£¨ì…˜ í…ŒìŠ¤íŠ¸ ê±´ë„ˆë›°ê¸°')
    
    args = parser.parse_args()
    
    # TensorFlow CPU ì„¤ì •
    setup_tensorflow_cpu()
    
    # ì‹œìŠ¤í…œ ì •ë³´ ì¶œë ¥
    print_system_info()
    
    # TensorFlow ì •ë³´ ì¶œë ¥
    print(f"\nTensorFlow ë²„ì „: {tf.__version__}")
    print(f"ì‚¬ìš© ê°€ëŠ¥í•œ CPU: {len(tf.config.list_physical_devices('CPU'))}")
    
    # ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§ ì‹œì‘
    monitor = ResourceMonitor(interval=0.5)
    monitor.start_monitoring()
    
    print(f"\nğŸ”¥ TensorFlow CPU ì§‘ì•½ì  í…ŒìŠ¤íŠ¸ ì‹œì‘ (ì§€ì† ì‹œê°„: {args.duration}ì´ˆ)")
    print("=" * 60)
    
    start_time = time.time()
    
    try:
        # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        test_results = {}
        
        # 1. í–‰ë ¬ ì—°ì‚° í…ŒìŠ¤íŠ¸
        print("\n1. í–‰ë ¬ ì—°ì‚° í…ŒìŠ¤íŠ¸")
        result = cpu_intensive_matrix_operations(
            num_iterations=args.matrix_iterations,
            matrix_size=args.matrix_size
        )
        test_results['matrix_operations'] = result
        
        # 2. ë³‘ë ¬ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸
        if not args.skip_parallel:
            print("\n2. ë³‘ë ¬ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸")
            result = cpu_parallel_tensorflow_ops()
            test_results['parallel_processing'] = result
        
        # 3. ì‹ ê²½ë§ í•™ìŠµ í…ŒìŠ¤íŠ¸
        if not args.skip_training:
            print("\n3. ì‹ ê²½ë§ í•™ìŠµ í…ŒìŠ¤íŠ¸")
            result = neural_network_cpu_training(epochs=args.epochs)
            test_results['neural_network'] = result
        
        # 4. ì»¨ë³¼ë£¨ì…˜ í…ŒìŠ¤íŠ¸
        if not args.skip_conv:
            print("\n4. ì»¨ë³¼ë£¨ì…˜ í…ŒìŠ¤íŠ¸")
            convolution_cpu_intensive(num_iterations=50)
            test_results['convolution'] = True
        
        # 5. ìˆ˜í•™ì  ì§‘ì•½ì  ì—°ì‚°
        print("\n5. ìˆ˜í•™ì  ì§‘ì•½ì  ì—°ì‚°")
        mathematical_intensive_operations(num_iterations=200)
        test_results['mathematical_ops'] = True
        
        # ë‚¨ì€ ì‹œê°„ ë™ì•ˆ ì¶”ê°€ í–‰ë ¬ ì—°ì‚° ìˆ˜í–‰
        elapsed_time = time.time() - start_time
        remaining_time = args.duration - elapsed_time
        
        if remaining_time > 10:
            print(f"\n6. ì¶”ê°€ í–‰ë ¬ ì—°ì‚° ({remaining_time:.1f}ì´ˆ ë™ì•ˆ)")
            extra_iterations = max(20, int(remaining_time / 3))
            result = cpu_intensive_matrix_operations(
                num_iterations=extra_iterations,
                matrix_size=1000
            )
            test_results['extra_operations'] = result
        
    except KeyboardInterrupt:
        print("\ní…ŒìŠ¤íŠ¸ê°€ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"\ní…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
    finally:
        # ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§ ì¢…ë£Œ
        monitor.stop_monitoring()
        monitor.print_summary()
        
        # ìµœì¢… ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ í™•ì¸
        final_usage = monitor.get_current_usage()
        print(f"\nìµœì¢… ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰:")
        print(f"CPU: {final_usage.get('cpu_percent', 0):.1f}%")
        print(f"Memory: {final_usage.get('memory_percent', 0):.1f}%")
        
        print("\nğŸ¯ TensorFlow CPU ì§‘ì•½ì  í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        print("=" * 60)


if __name__ == "__main__":
    main() 