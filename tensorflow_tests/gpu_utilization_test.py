"""
TensorFlow GPU ì‚¬ìš©ë¥  ì§‘ì•½ì  í…ŒìŠ¤íŠ¸
ì´ í…ŒìŠ¤íŠ¸ëŠ” GPU ì‚¬ìš©ë¥ ì„ ìµœëŒ€í™”í•˜ì—¬ GPU í™œìš©ë„ ëª¨ë‹ˆí„°ë§ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.
"""

import tensorflow as tf
import numpy as np
import time
import argparse
import sys
import os
import threading
from concurrent.futures import ThreadPoolExecutor

# Add utils directory to path
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))
from utils.resource_monitor import ResourceMonitor, print_system_info


def setup_tensorflow_gpu():
    """TensorFlow GPU ì„¤ì •"""
    gpus = tf.config.list_physical_devices('GPU')
    if gpus:
        try:
            for gpu in gpus:
                tf.config.experimental.set_memory_growth(gpu, True)
            print(f"GPU ì„¤ì • ì™„ë£Œ: {len(gpus)}ê°œ GPU ì‚¬ìš© ê°€ëŠ¥")
            return True
        except RuntimeError as e:
            print(f"GPU ì„¤ì • ì˜¤ë¥˜: {e}")
            return False
    else:
        print("âš ï¸  GPUë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. CPU ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤.")
        return False


def parallel_gpu_matrix_operations(num_operations=1000, matrix_size=2000):
    """ë³‘ë ¬ GPU í–‰ë ¬ ì—°ì‚°"""
    if not tf.config.list_physical_devices('GPU'):
        print("GPUê°€ ì‚¬ìš© ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤. í…ŒìŠ¤íŠ¸ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
        return
    
    print(f"ë³‘ë ¬ GPU í–‰ë ¬ ì—°ì‚°: {num_operations} ì—°ì‚°, í¬ê¸°: {matrix_size}")
    
    def matrix_worker(worker_id, operations_per_worker):
        """ê° ì›Œì»¤ì—ì„œ ì‹¤í–‰í•  í–‰ë ¬ ì—°ì‚°"""
        with tf.device('/GPU:0'):
            for i in range(operations_per_worker):
                # ë‹¤ì–‘í•œ í–‰ë ¬ ì—°ì‚°
                a = tf.random.normal([matrix_size, matrix_size])
                b = tf.random.normal([matrix_size, matrix_size])
                
                # í–‰ë ¬ ê³±ì…ˆ
                c = tf.matmul(a, b)
                
                # ê³ ìœ ê°’ ë¶„í•´ (ê³„ì‚° ì§‘ì•½ì )
                if i % 10 == 0:
                    try:
                        eigenvalues = tf.linalg.eigvals(c[:500, :500])
                    except:
                        pass
                
                # ì‚¼ê°í•¨ìˆ˜ ì—°ì‚°
                d = tf.sin(c) + tf.cos(c) + tf.tan(tf.clip_by_value(c, -1, 1))
                
                # ì§€ìˆ˜ ë° ë¡œê·¸ ì—°ì‚°
                e = tf.exp(tf.clip_by_value(d, -5, 5))
                f = tf.math.log(tf.abs(e) + 1e-8)
                
                # ì—­í–‰ë ¬ ê³„ì‚°
                try:
                    g = tf.linalg.inv(f + tf.eye(matrix_size) * 1e-3)
                except:
                    g = f
    
    # ë³‘ë ¬ ì‹¤í–‰
    num_workers = 4
    operations_per_worker = num_operations // num_workers
    
    with ThreadPoolExecutor(max_workers=num_workers) as executor:
        futures = []
        for i in range(num_workers):
            future = executor.submit(matrix_worker, i, operations_per_worker)
            futures.append(future)
        
        # ëª¨ë“  ì‘ì—… ì™„ë£Œ ëŒ€ê¸°
        for future in futures:
            try:
                future.result()
            except Exception as e:
                print(f"ì›Œì»¤ ì‘ì—… ì¤‘ ì˜¤ë¥˜: {e}")


def convolution_gpu_intensive(num_iterations=200, batch_size=16):
    """GPU ì§‘ì•½ì  ì»¨ë³¼ë£¨ì…˜ ì—°ì‚°"""
    if not tf.config.list_physical_devices('GPU'):
        print("GPUê°€ ì‚¬ìš© ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤. í…ŒìŠ¤íŠ¸ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
        return
    
    print(f"GPU ì»¨ë³¼ë£¨ì…˜ ì§‘ì•½ì  í…ŒìŠ¤íŠ¸: {num_iterations} ë°˜ë³µ, ë°°ì¹˜: {batch_size}")
    
    with tf.device('/GPU:0'):
        # ì»¨ë³¼ë£¨ì…˜ ë„¤íŠ¸ì›Œí¬ ìƒì„±
        model = tf.keras.Sequential([
            tf.keras.layers.Conv2D(64, (3, 3), activation='relu', input_shape=(224, 224, 3)),
            tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),
            tf.keras.layers.MaxPooling2D((2, 2)),
            tf.keras.layers.Conv2D(256, (3, 3), activation='relu'),
            tf.keras.layers.Conv2D(512, (3, 3), activation='relu'),
            tf.keras.layers.MaxPooling2D((2, 2)),
            tf.keras.layers.Conv2D(1024, (3, 3), activation='relu'),
            tf.keras.layers.GlobalAveragePooling2D(),
            tf.keras.layers.Dense(512, activation='relu'),
            tf.keras.layers.Dense(10, activation='softmax')
        ])
        
        model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')
        
        for i in range(num_iterations):
            try:
                # ëœë¤ ì´ë¯¸ì§€ ë°ì´í„° ìƒì„±
                X = tf.random.normal([batch_size, 224, 224, 3])
                y = tf.random.uniform([batch_size], 0, 10, dtype=tf.int32)
                
                # í•™ìŠµ ìŠ¤í…
                with tf.GradientTape() as tape:
                    predictions = model(X, training=True)
                    loss = tf.keras.losses.sparse_categorical_crossentropy(y, predictions)
                    loss = tf.reduce_mean(loss)
                
                gradients = tape.gradient(loss, model.trainable_variables)
                model.optimizer.apply_gradients(zip(gradients, model.trainable_variables))
                
                if i % 20 == 0:
                    print(f"  ì»¨ë³¼ë£¨ì…˜ ë°˜ë³µ {i}/{num_iterations}")
                    
            except tf.errors.ResourceExhaustedError:
                print(f"  GPU ë©”ëª¨ë¦¬ ë¶€ì¡±ìœ¼ë¡œ ë°˜ë³µ {i}ì—ì„œ ì¤‘ë‹¨")
                break


def fft_gpu_intensive(num_iterations=500, signal_size=8192):
    """GPU ì§‘ì•½ì  FFT ì—°ì‚°"""
    if not tf.config.list_physical_devices('GPU'):
        print("GPUê°€ ì‚¬ìš© ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤. í…ŒìŠ¤íŠ¸ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
        return
    
    print(f"GPU FFT ì§‘ì•½ì  í…ŒìŠ¤íŠ¸: {num_iterations} ë°˜ë³µ, ì‹ í˜¸ í¬ê¸°: {signal_size}")
    
    with tf.device('/GPU:0'):
        for i in range(num_iterations):
            # ë³µì¡í•œ ì‹ í˜¸ ìƒì„±
            real_signal = tf.random.normal([signal_size])
            imag_signal = tf.random.normal([signal_size])
            complex_signal = tf.complex(real_signal, imag_signal)
            
            # FFT ì—°ì‚°
            fft_result = tf.signal.fft(complex_signal)
            
            # ì—­ FFT
            ifft_result = tf.signal.ifft(fft_result)
            
            # 2D FFT (ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹œë®¬ë ˆì´ì…˜)
            if i % 10 == 0:
                image_size = int(np.sqrt(signal_size))
                if image_size * image_size <= signal_size:
                    image = tf.reshape(real_signal[:image_size*image_size], [image_size, image_size])
                    image_complex = tf.cast(image, tf.complex64)
                    fft_2d = tf.signal.fft2d(image_complex)
                    ifft_2d = tf.signal.ifft2d(fft_2d)
            
            # ìŠ¤í™íŠ¸ëŸ¼ ë¶„ì„
            power_spectrum = tf.abs(fft_result) ** 2
            
            if i % 50 == 0:
                print(f"  FFT ë°˜ë³µ {i}/{num_iterations}")


def compute_intensive_gpu_operations(num_iterations=300):
    """GPU ê³„ì‚° ì§‘ì•½ì  ì—°ì‚°"""
    if not tf.config.list_physical_devices('GPU'):
        print("GPUê°€ ì‚¬ìš© ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤. í…ŒìŠ¤íŠ¸ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
        return
    
    print(f"GPU ê³„ì‚° ì§‘ì•½ì  ì—°ì‚°: {num_iterations} ë°˜ë³µ")
    
    with tf.device('/GPU:0'):
        for i in range(num_iterations):
            # ëŒ€ìš©ëŸ‰ í…ì„œ ìƒì„±
            size = 2000
            a = tf.random.normal([size, size])
            b = tf.random.normal([size, size])
            
            # ë³µì¡í•œ ìˆ˜í•™ ì—°ì‚°ë“¤
            c = tf.matmul(a, b)
            d = tf.sin(c) * tf.cos(c) + tf.tan(tf.clip_by_value(c, -1, 1))
            e = tf.exp(tf.clip_by_value(d, -5, 5))
            f = tf.math.log(tf.abs(e) + 1e-8)
            g = tf.sqrt(tf.abs(f) + 1e-8)
            h = tf.pow(tf.abs(g), 0.5)
            
            # í†µê³„ì  ì—°ì‚°
            mean_val = tf.reduce_mean(h)
            std_val = tf.math.reduce_std(h)
            max_val = tf.reduce_max(h)
            min_val = tf.reduce_min(h)
            
            # ì†ŒíŒ… ì—°ì‚°
            if i % 20 == 0:
                sorted_vals = tf.sort(tf.reshape(h, [-1]))
            
            # ì¡°ê±´ë¶€ ì—°ì‚°
            mask = h > mean_val
            filtered = tf.where(mask, h, tf.zeros_like(h))
            
            if i % 30 == 0:
                print(f"  ê³„ì‚° ì§‘ì•½ì  ë°˜ë³µ {i}/{num_iterations}")


def mixed_precision_gpu_test(num_iterations=200):
    """GPU í˜¼í•© ì •ë°€ë„ í…ŒìŠ¤íŠ¸"""
    if not tf.config.list_physical_devices('GPU'):
        print("GPUê°€ ì‚¬ìš© ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤. í…ŒìŠ¤íŠ¸ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
        return
    
    print(f"GPU í˜¼í•© ì •ë°€ë„ í…ŒìŠ¤íŠ¸: {num_iterations} ë°˜ë³µ")
    
    with tf.device('/GPU:0'):
        # í˜¼í•© ì •ë°€ë„ ì •ì±… ì„¤ì •
        policy = tf.keras.mixed_precision.Policy('mixed_float16')
        tf.keras.mixed_precision.set_global_policy(policy)
        
        # ëª¨ë¸ ìƒì„±
        model = tf.keras.Sequential([
            tf.keras.layers.Dense(2048, activation='relu', input_shape=(1024,)),
            tf.keras.layers.Dense(1024, activation='relu'),
            tf.keras.layers.Dense(512, activation='relu'),
            tf.keras.layers.Dense(256, activation='relu'),
            tf.keras.layers.Dense(128, activation='relu'),
            tf.keras.layers.Dense(10, activation='softmax', dtype='float32')  # ì¶œë ¥ì€ float32
        ])
        
        optimizer = tf.keras.optimizers.Adam()
        
        for i in range(num_iterations):
            try:
                # ë°°ì¹˜ ë°ì´í„° ìƒì„±
                X = tf.random.normal([64, 1024])
                y = tf.random.uniform([64], 0, 10, dtype=tf.int32)
                
                with tf.GradientTape() as tape:
                    predictions = model(X, training=True)
                    loss = tf.keras.losses.sparse_categorical_crossentropy(y, predictions)
                    loss = tf.reduce_mean(loss)
                    
                    # ì†ì‹¤ ìŠ¤ì¼€ì¼ë§
                    scaled_loss = optimizer.get_scaled_loss(loss)
                
                # ê·¸ë˜ë””ì–¸íŠ¸ ê³„ì‚°
                scaled_gradients = tape.gradient(scaled_loss, model.trainable_variables)
                gradients = optimizer.get_unscaled_gradients(scaled_gradients)
                
                # ê·¸ë˜ë””ì–¸íŠ¸ ì ìš©
                optimizer.apply_gradients(zip(gradients, model.trainable_variables))
                
                if i % 20 == 0:
                    print(f"  í˜¼í•© ì •ë°€ë„ ë°˜ë³µ {i}/{num_iterations}")
                    
            except tf.errors.ResourceExhaustedError:
                print(f"  GPU ë©”ëª¨ë¦¬ ë¶€ì¡±ìœ¼ë¡œ ë°˜ë³µ {i}ì—ì„œ ì¤‘ë‹¨")
                break
        
        # ì •ì±… ë¦¬ì…‹
        tf.keras.mixed_precision.set_global_policy('float32')


def main():
    parser = argparse.ArgumentParser(description='TensorFlow GPU ì‚¬ìš©ë¥  ì§‘ì•½ì  í…ŒìŠ¤íŠ¸')
    parser.add_argument('--duration', type=int, default=240, help='í…ŒìŠ¤íŠ¸ ì§€ì† ì‹œê°„ (ì´ˆ)')
    parser.add_argument('--matrix-ops', type=int, default=400, help='í–‰ë ¬ ì—°ì‚° íšŸìˆ˜')
    parser.add_argument('--conv-iterations', type=int, default=100, help='ì»¨ë³¼ë£¨ì…˜ ë°˜ë³µ íšŸìˆ˜')
    parser.add_argument('--skip-conv', action='store_true', help='ì»¨ë³¼ë£¨ì…˜ í…ŒìŠ¤íŠ¸ ê±´ë„ˆë›°ê¸°')
    parser.add_argument('--skip-fft', action='store_true', help='FFT í…ŒìŠ¤íŠ¸ ê±´ë„ˆë›°ê¸°')
    parser.add_argument('--skip-mixed-precision', action='store_true', help='í˜¼í•© ì •ë°€ë„ í…ŒìŠ¤íŠ¸ ê±´ë„ˆë›°ê¸°')
    
    args = parser.parse_args()
    
    # TensorFlow GPU ì„¤ì •
    gpu_available = setup_tensorflow_gpu()
    
    # ì‹œìŠ¤í…œ ì •ë³´ ì¶œë ¥
    print_system_info()
    
    # TensorFlow ì •ë³´
    print(f"\nTensorFlow ë²„ì „: {tf.__version__}")
    if gpu_available:
        gpus = tf.config.list_physical_devices('GPU')
        print(f"ì‚¬ìš© ê°€ëŠ¥í•œ GPU: {len(gpus)}")
    
    # ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§ ì‹œì‘
    monitor = ResourceMonitor(interval=0.5)
    monitor.start_monitoring()
    
    print(f"\nğŸš€ TensorFlow GPU ì‚¬ìš©ë¥  ì§‘ì•½ì  í…ŒìŠ¤íŠ¸ ì‹œì‘ (ì§€ì† ì‹œê°„: {args.duration}ì´ˆ)")
    print("=" * 60)
    
    start_time = time.time()
    
    try:
        # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        
        # 1. ë³‘ë ¬ í–‰ë ¬ ì—°ì‚°
        print("\n1. ë³‘ë ¬ GPU í–‰ë ¬ ì—°ì‚°")
        parallel_gpu_matrix_operations(
            num_operations=args.matrix_ops,
            matrix_size=1500
        )
        
        # 2. ì»¨ë³¼ë£¨ì…˜ ì§‘ì•½ì  í…ŒìŠ¤íŠ¸
        if not args.skip_conv:
            print("\n2. GPU ì»¨ë³¼ë£¨ì…˜ ì§‘ì•½ì  í…ŒìŠ¤íŠ¸")
            convolution_gpu_intensive(
                num_iterations=args.conv_iterations,
                batch_size=8
            )
        
        # 3. FFT ì§‘ì•½ì  í…ŒìŠ¤íŠ¸
        if not args.skip_fft:
            print("\n3. GPU FFT ì§‘ì•½ì  í…ŒìŠ¤íŠ¸")
            fft_gpu_intensive(
                num_iterations=200,
                signal_size=4096
            )
        
        # 4. ê³„ì‚° ì§‘ì•½ì  ì—°ì‚°
        print("\n4. GPU ê³„ì‚° ì§‘ì•½ì  ì—°ì‚°")
        compute_intensive_gpu_operations(num_iterations=150)
        
        # 5. í˜¼í•© ì •ë°€ë„ í…ŒìŠ¤íŠ¸
        if not args.skip_mixed_precision:
            print("\n5. GPU í˜¼í•© ì •ë°€ë„ í…ŒìŠ¤íŠ¸")
            mixed_precision_gpu_test(num_iterations=100)
        
        # ë‚¨ì€ ì‹œê°„ ë™ì•ˆ ì¶”ê°€ ì—°ì‚° ìˆ˜í–‰
        elapsed_time = time.time() - start_time
        remaining_time = args.duration - elapsed_time
        
        if remaining_time > 20:
            print(f"\n6. ì¶”ê°€ ë³‘ë ¬ ì—°ì‚° ({remaining_time:.1f}ì´ˆ ë™ì•ˆ)")
            extra_operations = max(100, int(remaining_time * 3))
            parallel_gpu_matrix_operations(
                num_operations=extra_operations,
                matrix_size=1200
            )
        
    except KeyboardInterrupt:
        print("\ní…ŒìŠ¤íŠ¸ê°€ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"\ní…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
    finally:
        # ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§ ì¢…ë£Œ
        monitor.stop_monitoring()
        monitor.print_summary()
        
        # ìµœì¢… ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ í™•ì¸
        final_usage = monitor.get_current_usage()
        print(f"\nìµœì¢… ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰:")
        if gpu_available:
            for i in range(len(tf.config.list_physical_devices('GPU'))):
                gpu_utilization = final_usage.get(f'gpu_{i}_utilization', 0)
                print(f"GPU {i} ì‚¬ìš©ë¥ : {gpu_utilization}%")
        
        print("\nğŸ¯ TensorFlow GPU ì‚¬ìš©ë¥  ì§‘ì•½ì  í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        print("=" * 60)


if __name__ == "__main__":
    main() 